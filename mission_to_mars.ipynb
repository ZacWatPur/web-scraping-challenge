{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pymongo\n",
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the surface of Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming url for scraping\n",
    "\n",
    "mars_news = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# link to url named\n",
    "\n",
    "response = requests.get(mars_news)\n",
    "\n",
    "html = response.text\n",
    "\n",
    "mars_soup = BeautifulSoup(html, 'html.parser')\n",
    "mars_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping of the Content Titles\n",
    "mars_results = mars_soup.find_all('div', class_ = \"content_title\")\n",
    "\n",
    "mars_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for the titles\n",
    "mars_titles = []\n",
    "\n",
    "# Running a for loop to deposit titles in the list\n",
    "\n",
    "for result in mars_results:\n",
    "    # Identifying the anchor\n",
    "    if (result.a):\n",
    "        # There must be text\n",
    "        if (result.a.text):\n",
    "            # Appending title to list\n",
    "            mars_titles.append(result)\n",
    "            \n",
    "mars_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text to only show titles, stripping the HTML coding syntax\n",
    "stripped_mars_titles = []\n",
    "\n",
    "for x in range(len(mars_titles)):\n",
    "    temp = mars_titles[x].text\n",
    "    new_temp = temp.strip('\\n\\n')\n",
    "    stripped_mars_titles.append(new_temp)\n",
    "        \n",
    "stripped_mars_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to grab the sub text for the titles\n",
    "\n",
    "para_results = mars_soup.find_all('div', class_ = \"rollover_description_inner\")\n",
    "\n",
    "para_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for cleaned up text\n",
    "stripped_paras = []\n",
    "\n",
    "for y in range(len(para_results)):\n",
    "    temp = para_results[y].text\n",
    "    newtemp = temp.strip('\\n\\n')\n",
    "    stripped_paras.append(newtemp)\n",
    "    \n",
    "stripped_paras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for the Image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning url for image capture\n",
    "urlI = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html'\n",
    "\n",
    "response = requests.get(urlI)\n",
    "\n",
    "html = response.text\n",
    "\n",
    "mars_image = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making html more understandable\n",
    "\n",
    "print(mars_image.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating images\n",
    "images = mars_image.find_all('a', class_ = \"showimg fancybox-thumbs\")\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning image specific path\n",
    "pic = \"image/featured/mars1.jpg\"\n",
    "\n",
    "# creating url for image    \n",
    "feature_image_url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/' + pic\n",
    "feature_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Table Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://space-facts.com/mars/'\n",
    "response3 = requests.get(url)\n",
    "soup = BeautifulSoup(response3.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling table info\n",
    "mars_tables = pd.read_html(url)\n",
    "mars_tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming to dataframe for alterations\n",
    "mars_df = mars_tables[0]\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "mars_df.columns = ['Statistic', 'Measurement']\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripping out the :\n",
    "mars_ser = pd.Series(mars_df['Statistic'])\n",
    "mars_df['Statistic'] = mars_ser.str.strip(':')\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting Statistic as the index\n",
    "mars_df = mars_df.set_index('Statistic')\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting df back into html table\n",
    "html_mars_table = mars_df.to_html()\n",
    "html_mars_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving table\n",
    "mars_df.to_html('mars_html_table.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering hemispherical images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up windows browser with chromedriver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting url for alternate browser\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally got to the url for the images\n",
    "nextpage_urls = []\n",
    "imgtitles = []\n",
    "base_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "# HTML object\n",
    "html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# Retrieve all elements that contain hemisphere photo info\n",
    "divs = soup.find_all('div', class_='description')\n",
    "\n",
    "# Iterate through each div to pull titles and make list of hrefs to iterate through\n",
    "counter = 0\n",
    "for div in divs:\n",
    "        # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "    link = div.find('a')\n",
    "    href=link['href']\n",
    "    img_title = div.a.find('h3')\n",
    "    img_title = img_title.text\n",
    "    imgtitles.append(img_title)\n",
    "    next_page = base_url + href\n",
    "    nextpage_urls.append(next_page)\n",
    "    counter = counter+1\n",
    "    if (counter == 4):\n",
    "        break\n",
    "print(nextpage_urls)\n",
    "print(imgtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to pull images\n",
    "\n",
    "the_images = []\n",
    "for nextpage_url in nextpage_urls:\n",
    "    url = nextpage_url\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    link2 = soup.find('img', class_ = \"wide-image\")\n",
    "    finals = link2['src']\n",
    "    full_image = base_url + finals\n",
    "    the_images.append(full_image)\n",
    "    nextpage_urls = []\n",
    "    \n",
    "the_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating final list of dictionaries\n",
    "# values - imgtitles and my_images\n",
    "#ckeys- img_url and title\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "cerberus = {'title':imgtitles[0], 'img_url': the_images[0]}\n",
    "schiaparelli = {'title':imgtitles[1], 'img_url': the_images[1]}\n",
    "syrtis = {'title':imgtitles[2], 'img_url': the_images[2]}\n",
    "valles = {'title':imgtitles[3], 'img_url': the_images[3]}\n",
    "\n",
    "hemisphere_image_urls = [cerberus, schiaparelli, syrtis, valles]\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
